# Those arguments defines the training hyper-parameters
training:
    shuffle: True
    num_workers: 6
    batch_size: 16
    cuda: 1
    precompute_multi_scale: False # Compute multiscate features on cpu for faster training / inference
    epochs: 100
    grad_clip: -1
    base_lr: 0.001
    optim:
        optimizer:
            class: Adam
            params:
                lr: ${base_lr} # The path is cut from training
        scheduler: ${scheduler}
        bn_scheduler:
            class: BNMomentumScheduler
            bn_lambda: "step_decay"
            bn_momentum: 0.9
            params:
                bn_decay: 0.5
                decay_step : 200000
                bnm_clip : 1e-2
    weight_name: "latest" # Used during resume, select with model to load from [miou, macc, acc..., latest]
    enable_cudnn: True
    checkpoint_dir: ""
    resume: True

# Those arguments within experiment defines which model, dataset and task to be created for benchmarking
# parameters for Weights and Biases
wandb:
    project: default
    log: False
    notes:
    name:

    # parameters for TensorBoard Visualization
tensorboard:
    log: True
